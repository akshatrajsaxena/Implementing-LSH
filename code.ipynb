import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import normalize



def read_files():
    with open('ids.txt', 'r', encoding='utf-8') as f:
        ids = [line.strip() for line in f.readlines()]
    
    with open('texts.txt', 'r', encoding='utf-8') as f:
        texts = [line.strip() for line in f.readlines()]

    with open('items.json', 'r', encoding='utf-8') as f:
        ground_truth = json.load(f)

    return ids, texts, ground_truth







def vectorize_texts(texts):
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    tfidf_matrix = vectorizer.fit_transform(texts)
    return tfidf_matrix


def lsh_and_find_similar(tfidf_matrix, ids, n_neighbors=5):
    
    tfidf_matrix = normalize(tfidf_matrix)
    
    
    
    nn_model = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute', metric='cosine')
    nn_model.fit(tfidf_matrix)
    
    
    distances, indices = nn_model.kneighbors(tfidf_matrix)
    
    
    predicted_similar = {ids[i]: [ids[idx] for idx in indices[i][1:]] for i in range(len(ids))}  
    return predicted_similar


def evaluate(predicted_similar, ground_truth):
    scores = []
    
    for sample_id, predicted_items in predicted_similar.items():
        true_items = set(ground_truth[sample_id])
        predicted_items_set = set(predicted_items)
        
        
        intersection_count = len(true_items.intersection(predicted_items_set))
        scores.append(intersection_count)

    
    return scores


def plot_results(scores):
    
    plt.figure(figsize=(10, 5))
    plt.hist(scores, bins=6, edgecolor='black')
    plt.title('Histogram of Intersection Scores')
    plt.xlabel('Score (0-5)')
    plt.ylabel('Frequency')
    plt.show()
    
    
    plt.figure(figsize=(6, 5))
    plt.boxplot(scores)
    plt.title('Box Plot of Intersection Scores')
    plt.show()
    
    
    score_series = pd.Series(scores)
    print(score_series.describe())


def run_on_test_data(test_ids_file, test_texts_file, ids, texts, nn_model, vectorizer):
    
    with open(test_ids_file, 'r') as f:
        test_ids = [line.strip() for line in f.readlines()]
    
    with open(test_texts_file, 'r') as f:
        test_texts = [line.strip() for line in f.readlines()]
    
    
    test_tfidf_matrix = vectorizer.transform(test_texts)
    
    
    test_tfidf_matrix = normalize(test_tfidf_matrix)
    
    
    distances, indices = nn_model.kneighbors(test_tfidf_matrix)
    
    
    predicted_similar_test = {test_ids[i]: [ids[idx] for idx in indices[i][1:]] for i in range(len(test_ids))}
    
    return predicted_similar_test


if __name__ == '__main__':
    
    ids, texts, ground_truth = read_files()
    
    
    tfidf_matrix = vectorize_texts(texts)
    
    
    predicted_similar = lsh_and_find_similar(tfidf_matrix, ids)
    
    
    scores = evaluate(predicted_similar, ground_truth)
    
    
    plot_results(scores)
    
    
    
